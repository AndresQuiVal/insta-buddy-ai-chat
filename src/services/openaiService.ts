import { toast } from '@/hooks/use-toast';

// Using the API key provided by the user
const OPENAI_API_KEY = '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';

export interface OpenAIConfig {
  apiKey: string;
  model: string;
  temperature: number;
  maxTokens: number;
}

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

/**
 * Genera una respuesta de ChatGPT utilizando la API de OpenAI
 */
export const generateAIResponse = async (
  messages: ChatMessage[], 
  config: OpenAIConfig = {
    apiKey: OPENAI_API_KEY,
    model: 'gpt-4o', // Modelo por defecto
    temperature: 0.7,
    maxTokens: 500
  }
): Promise<string> => {
  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.apiKey}`
      },
      body: JSON.stringify({
        model: config.model,
        messages: messages,
        temperature: config.temperature,
        max_tokens: config.maxTokens
      })
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`Error en la API de OpenAI: ${error}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  } catch (error) {
    console.error('Error al generar respuesta con ChatGPT:', error);
    toast({
      title: "Error de ChatGPT",
      description: "No se pudo generar una respuesta. Verifica tu API key.",
      variant: "destructive"
    });
    return "Lo siento, tuve un problema al procesar tu mensaje. Por favor, int√©ntalo de nuevo m√°s tarde.";
  }
};

/**
 * Crea un sistema de prompt NATURAL y SUTIL para filtrar prospectos
 */
export const createStrategicSystemPrompt = (config: {
  idealClientTraits: string[];
  currentMatchPoints: number;
  metTraits: string[];
  conversationSummary?: string;
}): string => {
  const { idealClientTraits, currentMatchPoints, metTraits, conversationSummary } = config;
  const pendingTraits = idealClientTraits.filter(trait => !metTraits.includes(trait));
  const nextTrait = pendingTraits[0]; // Pr√≥xima caracter√≠stica a descubrir
  
  return `
Eres un VENDEDOR EXPERTO que tiene conversaciones GENUINAS y NATURALES para conocer mejor a los prospectos.

üéØ TU OBJETIVO SECRETO:
- Progreso: ${currentMatchPoints}/${idealClientTraits.length} caracter√≠sticas identificadas
- ‚úÖ YA IDENTIFICASTE: ${metTraits.length > 0 ? metTraits.join(' | ') : 'NINGUNA'}
- üîç A√öN NECESITAS DESCUBRIR: ${pendingTraits.join(' | ')}
- üéØ PR√ìXIMO OBJETIVO SUTIL: ${nextTrait || 'TODAS IDENTIFICADAS - BUSCAR LLAMADA/WHATSAPP'}

üó£Ô∏è TU ESTILO DE CONVERSACI√ìN:
${currentMatchPoints === 0 ? `
üåü INICIO - Conversaci√≥n natural y genuina
- Saluda de forma amigable y aut√©ntica
- Haz preguntas de CONEXI√ìN PERSONAL que indirectamente revelen: "${nextTrait}"
- NO preguntes directamente sobre la caracter√≠stica
- Genera CURIOSIDAD y construye RAPPORT
- EJEMPLO: En lugar de "¬øTe interesan los aviones?" ‚Üí "¬øQu√© tipo de cosas te gusta hacer en tu tiempo libre?"
` : currentMatchPoints < idealClientTraits.length ? `
üí¨ CONVERSACI√ìN ACTIVA - Sigue siendo natural
- Ya identificaste ${currentMatchPoints} caracter√≠sticas, te faltan ${pendingTraits.length}
- Haz preguntas de SEGUIMIENTO NATURAL que indirectamente revelen: "${nextTrait}"
- Conecta con lo que ya sabes del prospecto
- Muestra INTER√âS GENUINO en sus respuestas
- EJEMPLOS SUTILES seg√∫n la caracter√≠stica:
  * Para descubrir presupuesto: "¬øHas invertido en proyectos personales antes?" o "¬øQu√© tipo de decisiones importantes has tomado √∫ltimamente?"
  * Para descubrir ubicaci√≥n: "¬øC√≥mo est√° el clima por donde vives?" o "¬øDe qu√© parte del pa√≠s me escribes?"
  * Para descubrir necesidad: "¬øQu√© te motiv√≥ a buscar informaci√≥n sobre esto?" o "¬øHay algo espec√≠fico que te tiene pensando en esto?"
` : `
üèÜ PROSPECTO CALIFICADO - Momento de avanzar naturalmente
- ¬°Este prospecto cumple las ${idealClientTraits.length} caracter√≠sticas!
- AHORA s√≠ puedes ser m√°s directo sobre dar el siguiente paso
- Sugerir llamada o WhatsApp de forma NATURAL y GENUINA
- "Me encantar√≠a platicar m√°s contigo, ¬øtienes unos minutos para una llamada?" 
- "¬øTe parece si coordinamos una llamada r√°pida? Creo que te puedo ayudar mucho"
`}

üé≠ REGLAS DE CONVERSACI√ìN NATURAL:
1. S√â AUT√âNTICO - Habla como una persona real interesada en conocer al prospecto
2. ESCUCHA ACTIVAMENTE - Haz seguimiento a las respuestas que te den
3. CONECTA EMOCIONALMENTE - Muestra empat√≠a y comprensi√≥n
4. PREGUNTA POR CURIOSIDAD GENUINA - No por interrogatorio
5. CONSTRUYE RAPPORT ANTES de filtrar
6. NUNCA reveles que est√°s evaluando caracter√≠sticas espec√≠ficas
7. Si detectas una caracter√≠stica, NO la menciones directamente, solo t√≥mala en cuenta

üí° EJEMPLOS DE PREGUNTAS NATURALES Y SUTILES:
- "¬øQu√© te gusta hacer cuando no est√°s trabajando?"
- "¬øC√≥mo descubriste esto que me est√°s comentando?"
- "¬øQu√© es lo que m√°s te emociona de este tipo de cosas?"
- "¬øHas tenido experiencias similares antes?"
- "¬øQu√© te motiv√≥ a buscar informaci√≥n sobre esto?"
- "¬øC√≥mo te imaginas que esto podr√≠a ayudarte?"

üö´ NUNCA HAGAS:
- Preguntas que suenen como cuestionario
- Preguntas demasiado directas sobre las caracter√≠sticas
- Interrogatorios sin contexto
- Mencionar que est√°s "evaluando" al prospecto
- Preguntar m√∫ltiples cosas seguidas sin esperar respuesta

üí¨ TONO Y PERSONALIDAD:
- Amigable pero profesional
- Curioso pero no invasivo
- Genuinamente interesado en ayudar
- Natural y conversacional
- Emp√°tico y comprensivo

RESPONDE SOLO con tu siguiente mensaje natural y genuino, SIN explicaciones t√©cnicas.
  `.trim();
};

/**
 * Verifica si la configuraci√≥n de OpenAI est√° completa
 */
export const isOpenAIConfigured = (): boolean => {
  return OPENAI_API_KEY.trim() !== '';
};

/**
 * Genera una respuesta ULTRA ESTRAT√âGICA y PROACTIVA
 */
export const handleStrategicResponse = async (
  conversationHistory: ChatMessage[],
  currentMatchPoints: number,
  metTraits: string[],
  idealClientTraits: string[]
): Promise<string> => {
  try {
    console.log("üéØ GENERANDO RESPUESTA ULTRA ESTRAT√âGICA:");
    console.log(`üìä Progreso: ${currentMatchPoints}/${idealClientTraits.length} caracter√≠sticas`);
    console.log(`‚úÖ Cumplidas: ${metTraits.join(', ')}`);
    
    const pendingTraits = idealClientTraits.filter(trait => !metTraits.includes(trait));
    console.log(`üéØ Pendientes: ${pendingTraits.join(', ')}`);
    console.log(`‚ö° Pr√≥ximo objetivo: ${pendingTraits[0] || 'CONSEGUIR LLAMADA/WHATSAPP'}`);
    
    // Crear resumen estrat√©gico de la conversaci√≥n
    const conversationSummary = currentMatchPoints === 0 
      ? 'Conversaci√≥n inicial - establecer rapport y empezar filtrado'
      : `Progreso: ${currentMatchPoints}/${idealClientTraits.length} - continuar filtrado activo`;

    // Crear prompt ULTRA estrat√©gico
    const systemPrompt = createStrategicSystemPrompt({
      idealClientTraits,
      currentMatchPoints,
      metTraits,
      conversationSummary
    });

    const messages: ChatMessage[] = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory.slice(-10) // Solo √∫ltimos 10 mensajes para mantener contexto relevante
    ];

    console.log("üöÄ Enviando prompt ULTRA ESTRAT√âGICO a OpenAI...");
    
    const response = await generateAIResponse(messages, {
      apiKey: OPENAI_API_KEY,
      model: 'gpt-4o',
      temperature: 0.9, // M√°s creativo para conversaciones naturales pero directas
      maxTokens: 150 // Mensajes concisos y directos
    });

    console.log("‚ö° RESPUESTA ESTRAT√âGICA:", response);
    
    // Log del progreso
    if (currentMatchPoints === idealClientTraits.length) {
      console.log("üèÜ PROSPECTO CALIFICADO - Respuesta debe buscar llamada/WhatsApp");
    } else {
      console.log(`üéØ RESPUESTA debe descubrir: ${pendingTraits[0]}`);
    }
    
    return response;
    
  } catch (error) {
    console.error('‚ùå Error al generar respuesta estrat√©gica:', error);
    return "¬°Hola! Me da mucho gusto conectar contigo. Cu√©ntame, ¬øqu√© tipo de cosas te interesan? üòä";
  }
};

/**
 * Genera una respuesta autom√°tica LEGACY (mantenido para compatibilidad)
 */
export const handleAutomaticResponse = async (
  message: string, 
  conversationHistory: ChatMessage[],
  businessConfig: {
    businessName: string;
    businessDescription: string;
    tone: string;
    idealClientTraits: string[];
  },
  customPrompt?: string
): Promise<string> => {
  try {
    // Obtener datos de an√°lisis previo desde localStorage
    const savedConversationsStr = localStorage.getItem('hower-conversations');
    let currentMatchPoints = 0;
    let metTraits: string[] = [];
    
    if (savedConversationsStr) {
      const conversations = JSON.parse(savedConversationsStr);
      // Buscar la conversaci√≥n actual (esto es una aproximaci√≥n)
      const lastConv = conversations[conversations.length - 1];
      if (lastConv) {
        currentMatchPoints = lastConv.matchPoints || 0;
        metTraits = lastConv.metTraits || [];
      }
    }

    // Usar el nuevo sistema ULTRA estrat√©gico
    return await handleStrategicResponse(
      conversationHistory,
      currentMatchPoints,
      metTraits,
      businessConfig.idealClientTraits
    );
    
  } catch (error) {
    console.error('Error al manejar respuesta autom√°tica:', error);
    return "Lo siento, no pude procesar tu mensaje en este momento.";
  }
};
